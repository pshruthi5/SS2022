{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ddd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STUDENT NAME: SHRUTHI\n",
    "#STUDENT ID: 801218392\n",
    "#HOMEWORK 3 QUESTION 2-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13686c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4fc8d28b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c273d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9deb52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = 'C:/Users/Shruthi/Documents/HWs/RTML/hw2/data'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b01be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0328ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                            padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac37d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "                    *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.dropout = nn.Dropout2d(p=0.3)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = self.dropout(out)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cce7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet10() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43f440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn,\n",
    "                        train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            #imgs = imgs.to(device=device)\n",
    "            #labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "                          for p in model.parameters())  # <1>\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414a59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-26 16:43:06.590779 Epoch 1, Training loss 1.7995484334123715\n",
      "2022-03-26 16:58:58.924860 Epoch 10, Training loss 0.9947779642041686\n",
      "2022-03-26 17:16:42.123520 Epoch 20, Training loss 0.8372888619942433\n",
      "2022-03-26 17:34:30.658496 Epoch 30, Training loss 0.7557542784820737\n",
      "2022-03-26 17:52:44.094720 Epoch 40, Training loss 0.7070414215859855\n",
      "2022-03-26 18:10:16.738374 Epoch 50, Training loss 0.6651053291833614\n",
      "2022-03-26 18:29:35.255554 Epoch 60, Training loss 0.6406844511361378\n",
      "2022-03-26 18:47:18.420692 Epoch 70, Training loss 0.6158630244262383\n",
      "2022-03-26 19:05:52.078059 Epoch 80, Training loss 0.60630457259505\n",
      "2022-03-26 19:25:23.001104 Epoch 90, Training loss 0.5917978069132857\n",
      "2022-03-26 19:45:34.890741 Epoch 100, Training loss 0.5779045486389218\n",
      "2022-03-26 20:05:56.208153 Epoch 110, Training loss 0.5723788283212715\n",
      "2022-03-26 20:26:16.989802 Epoch 120, Training loss 0.5641029179096222\n",
      "2022-03-26 20:46:04.986748 Epoch 130, Training loss 0.567678845675705\n",
      "2022-03-26 21:05:40.577806 Epoch 140, Training loss 0.555553322557903\n",
      "2022-03-26 21:25:53.783776 Epoch 150, Training loss 0.5516463085208707\n",
      "2022-03-26 21:44:57.656243 Epoch 160, Training loss 0.5528526412099218\n",
      "2022-03-26 22:04:25.684258 Epoch 170, Training loss 0.5513340504196904\n",
      "2022-03-26 22:24:10.483437 Epoch 180, Training loss 0.5448304724586589\n",
      "2022-03-26 22:44:05.216101 Epoch 190, Training loss 0.5470671991786689\n",
      "2022-03-26 23:02:49.144615 Epoch 200, Training loss 0.5351228172440663\n",
      "2022-03-26 23:22:25.082610 Epoch 210, Training loss 0.5426106077745138\n",
      "2022-03-26 23:42:28.419286 Epoch 220, Training loss 0.5406741389380697\n",
      "2022-03-27 00:01:54.215199 Epoch 230, Training loss 0.5398462831288042\n",
      "2022-03-27 00:20:54.397327 Epoch 240, Training loss 0.5358635858654062\n",
      "2022-03-27 00:40:38.356026 Epoch 250, Training loss 0.5401448215288884\n",
      "2022-03-27 01:00:06.081175 Epoch 260, Training loss 0.5321739059503731\n",
      "2022-03-27 01:19:05.660273 Epoch 270, Training loss 0.537380655860657\n",
      "2022-03-27 01:39:20.744443 Epoch 280, Training loss 0.5290294148580498\n",
      "2022-03-27 02:00:06.301758 Epoch 290, Training loss 0.5267683655176016\n",
      "2022-03-27 02:20:42.116726 Epoch 300, Training loss 0.5280674433388064\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop_l2reg(  # <5>\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52ed71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.85\n",
      "Accuracy val: 0.73\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40b81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module Dropout2d is treated as a zero-op.\n",
      "Warning: module ResNet10 is treated as a zero-op.\n",
      "ResNet10(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.178% Params, 0.001 GMac, 3.709% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.3, inplace=False)\n",
      "  (fc1): Linear(0.066 M, 86.190% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.07 k \n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "net = model\n",
    "macs, params = get_model_complexity_info(net, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e09689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76074, [864, 32, 9216, 32, 32, 65536, 32, 320, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
