{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STUDENT NAME: SHRUTHI\n",
    "#STUDENT ID: 801218392\n",
    "#HOMEWORK 3 QUESTION 2-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c243484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x255f53c28b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307d68d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a62ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a3cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = 'C:/Users/Shruthi/Documents/HWs/RTML/hw2/data'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d00326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0309bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                            padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bc712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "                    *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab32478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet10() \n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25693198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    correctt=0\n",
    "    totalt=0\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            #imgs=imgs.to(device)\n",
    "            #labels=labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs)#  <2>  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in train_loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "            totalt += labels.shape[0]\n",
    "            correctt += int((predicted == labels).sum())\n",
    "            acctt = float(correctt/totalt)\n",
    "    print(\"Accuracy in Training: \",acctt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32b6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-27 02:37:00.003336 Epoch 1, Training loss 1.6815451666369767\n",
      "2022-03-27 03:00:59.173803 Epoch 10, Training loss 0.7980956589169514\n",
      "2022-03-27 03:27:41.674281 Epoch 20, Training loss 0.606601014085438\n",
      "2022-03-27 03:56:43.787878 Epoch 30, Training loss 0.47809191528336165\n",
      "2022-03-27 04:25:21.062053 Epoch 40, Training loss 0.35900023292816813\n",
      "2022-03-27 04:53:17.845934 Epoch 50, Training loss 0.2792852040084884\n",
      "2022-03-27 05:21:28.823366 Epoch 60, Training loss 0.2196802511868422\n",
      "2022-03-27 05:49:55.835532 Epoch 70, Training loss 0.16882229157868783\n",
      "2022-03-27 06:17:55.786240 Epoch 80, Training loss 0.152107960629084\n",
      "2022-03-27 06:44:43.138128 Epoch 90, Training loss 0.12993949261801246\n",
      "2022-03-27 07:10:29.395942 Epoch 100, Training loss 0.10447808772997211\n",
      "2022-03-27 07:36:27.329869 Epoch 110, Training loss 0.11442594168424282\n",
      "2022-03-27 08:03:30.249520 Epoch 120, Training loss 0.09205280789418284\n",
      "2022-03-27 08:31:57.212658 Epoch 130, Training loss 0.07889729469170188\n",
      "2022-03-27 08:59:42.119133 Epoch 140, Training loss 0.07106426535168296\n",
      "2022-03-27 09:27:11.293497 Epoch 150, Training loss 0.07555806022756698\n",
      "2022-03-27 09:54:48.874984 Epoch 160, Training loss 0.05994797683463258\n",
      "2022-03-27 10:22:28.106493 Epoch 170, Training loss 0.05949662654871143\n",
      "2022-03-27 10:50:23.957376 Epoch 180, Training loss 0.04626627926583863\n",
      "2022-03-27 11:18:16.424837 Epoch 190, Training loss 0.03935749979150515\n",
      "2022-03-27 11:47:15.224650 Epoch 200, Training loss 0.04587040172764481\n",
      "2022-03-27 12:17:00.897228 Epoch 210, Training loss 0.039831905112498504\n",
      "2022-03-27 12:46:31.645110 Epoch 220, Training loss 0.03562043170580733\n",
      "2022-03-27 13:15:40.346065 Epoch 230, Training loss 0.06738792697878128\n",
      "2022-03-27 13:44:21.975617 Epoch 240, Training loss 0.03561595365831368\n",
      "2022-03-27 14:13:05.208333 Epoch 250, Training loss 0.04428815314502832\n",
      "2022-03-27 14:41:38.003199 Epoch 260, Training loss 0.024998262995495096\n",
      "2022-03-27 15:10:39.254202 Epoch 270, Training loss 0.027392683771915723\n",
      "2022-03-27 15:39:12.586895 Epoch 280, Training loss 0.005834856073749699\n",
      "2022-03-27 16:06:02.744949 Epoch 290, Training loss 0.017754930573987842\n",
      "2022-03-27 16:33:19.380801 Epoch 300, Training loss 0.016664662105412696\n",
      "Accuracy in Training:  0.8797916666666666\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe5d6f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.99\n",
      "Accuracy val: 0.67\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b721a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module ResNet10 is treated as a zero-op.\n",
      "ResNet10(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.178% Params, 0.001 GMac, 3.709% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(0.066 M, 86.190% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.07 k \n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "net = model\n",
    "macs, params = get_model_complexity_info(net, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc976ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76074, [864, 32, 9216, 32, 32, 65536, 32, 320, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
